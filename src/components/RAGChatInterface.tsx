
import React, { useState } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Badge } from '@/components/ui/badge';
import { useRAGQueries, useCreateRAGQuery } from '@/hooks/useRAGQueries';
import { MessageSquare, Send, Bot, User, Clock, Zap } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';

interface RAGChatInterfaceProps {
  projectId: string;
}

const RAGChatInterface: React.FC<RAGChatInterfaceProps> = ({ projectId }) => {
  const [query, setQuery] = useState('');
  const { data: queries, isLoading } = useRAGQueries(projectId);
  const createQuery = useCreateRAGQuery();
  const { toast } = useToast();

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!query.trim()) return;

    const startTime = Date.now();
    
    try {
      // Simulate RAG processing - in real implementation, this would call your RAG service
      const simulatedResponse = `Based on the documents in your knowledge base, here's what I found regarding "${query}":

This is a simulated response that would normally be generated by your LLM after retrieving relevant document chunks. The system would:

1. Convert your query to embeddings
2. Search the vector database for similar content
3. Retrieve the most relevant document chunks
4. Send the context to the LLM for response generation

In a production environment, this would integrate with your vLLM service running LLaMA 3 70B.`;

      await createQuery.mutateAsync({
        project_id: projectId,
        query_text: query,
        response_text: simulatedResponse,
        retrieved_chunks: [
          { id: 'chunk1', text: 'Sample document chunk 1...', score: 0.95 },
          { id: 'chunk2', text: 'Sample document chunk 2...', score: 0.87 },
        ],
        llm_provider: 'llama3',
        tokens_used: Math.floor(Math.random() * 500) + 100,
        response_time_ms: Date.now() - startTime,
      });

      setQuery('');
      toast({
        title: "Query processed",
        description: "Your question has been answered using RAG.",
      });
    } catch (error) {
      toast({
        title: "Error",
        description: "Failed to process query. Please try again.",
        variant: "destructive",
      });
    }
  };

  return (
    <Card className="h-[600px] flex flex-col">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <MessageSquare className="h-5 w-5" />
          RAG Chat Interface
        </CardTitle>
      </CardHeader>
      <CardContent className="flex-1 flex flex-col p-0">
        <ScrollArea className="flex-1 p-4">
          <div className="space-y-4">
            {isLoading ? (
              <div className="text-center text-muted-foreground">Loading conversation...</div>
            ) : queries?.length === 0 ? (
              <div className="text-center text-muted-foreground">
                Start a conversation by asking a question about your documents.
              </div>
            ) : (
              queries?.map((q) => (
                <div key={q.id} className="space-y-3">
                  {/* User Query */}
                  <div className="flex items-start gap-3">
                    <div className="bg-primary text-primary-foreground rounded-full p-2">
                      <User className="h-4 w-4" />
                    </div>
                    <div className="flex-1">
                      <div className="bg-muted p-3 rounded-lg">
                        <p>{q.query_text}</p>
                      </div>
                      <div className="flex items-center gap-2 mt-1 text-xs text-muted-foreground">
                        <Clock className="h-3 w-3" />
                        {new Date(q.created_at).toLocaleTimeString()}
                      </div>
                    </div>
                  </div>

                  {/* Bot Response */}
                  {q.response_text && (
                    <div className="flex items-start gap-3">
                      <div className="bg-blue-600 text-white rounded-full p-2">
                        <Bot className="h-4 w-4" />
                      </div>
                      <div className="flex-1">
                        <div className="bg-blue-50 p-3 rounded-lg border border-blue-200">
                          <p className="whitespace-pre-wrap">{q.response_text}</p>
                        </div>
                        <div className="flex items-center gap-4 mt-2">
                          <div className="flex items-center gap-1 text-xs text-muted-foreground">
                            <Zap className="h-3 w-3" />
                            {q.tokens_used} tokens
                          </div>
                          {q.response_time_ms && (
                            <div className="flex items-center gap-1 text-xs text-muted-foreground">
                              <Clock className="h-3 w-3" />
                              {q.response_time_ms}ms
                            </div>
                          )}
                          <Badge variant="secondary" className="text-xs">
                            {q.llm_provider}
                          </Badge>
                        </div>
                        {q.retrieved_chunks.length > 0 && (
                          <div className="mt-2">
                            <details className="text-xs">
                              <summary className="cursor-pointer text-muted-foreground hover:text-foreground">
                                View retrieved chunks ({q.retrieved_chunks.length})
                              </summary>
                              <div className="mt-2 space-y-1">
                                {q.retrieved_chunks.map((chunk: any, idx: number) => (
                                  <div key={idx} className="bg-gray-50 p-2 rounded text-xs">
                                    <div className="font-medium">Chunk {idx + 1} (score: {chunk.score})</div>
                                    <div className="text-muted-foreground truncate">{chunk.text}</div>
                                  </div>
                                ))}
                              </div>
                            </details>
                          </div>
                        )}
                      </div>
                    </div>
                  )}
                </div>
              ))
            )}
          </div>
        </ScrollArea>

        <div className="border-t p-4">
          <form onSubmit={handleSubmit} className="flex gap-2">
            <Input
              value={query}
              onChange={(e) => setQuery(e.target.value)}
              placeholder="Ask a question about your documents..."
              disabled={createQuery.isPending}
              className="flex-1"
            />
            <Button type="submit" disabled={createQuery.isPending || !query.trim()}>
              {createQuery.isPending ? (
                <div className="h-4 w-4 animate-spin rounded-full border-2 border-current border-t-transparent" />
              ) : (
                <Send className="h-4 w-4" />
              )}
            </Button>
          </form>
        </div>
      </CardContent>
    </Card>
  );
};

export default RAGChatInterface;
